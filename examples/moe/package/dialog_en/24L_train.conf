# job settings
task_name="dialog_en_24L_train"
job_script="./scripts/distributed/train.sh"
queue="nlp-32g-0-yq01-k8s-gpu-v100-8"
nodes=1
permission="private"

# k8s
fs_name="fs_name"
fs_ugi="username,password"
force_reuse_output_path="True"
output_path="/hdfs/path/to/output"

# afs
afs_fs_name="afs_fs_name"
afs_fs_ugi="username,password"
remote_mount_point="/afs/path/"
local_mount_point="/root/paddlejob/workspace/env_run/data/"

# hdfs
hdfs_path="hdfs_path"
hdfs_ugi="username,password"
hdfs_python_package=""
hdfs_init_model="/hdfs/path/to/model"

# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./package/dialog_en/vocab.txt"
spm_model_file="./package/dialog_en/spm.model"
train_file="./data/example/train_filelist"
valid_file="./data/example/valid_filelist"
data_format="raw"
file_format="filelist"
config_path="./package/dialog_en/24L.json"

# training settings
init_params="/path/to/model"
in_tokens="true"
batch_size=8192
lr=1e-5
warmup_steps=0
weight_decay=0.01
num_epochs=20

log_steps=10
validation_steps=1000
save_steps=10000

log_dir="./log"
save_path="./output"
