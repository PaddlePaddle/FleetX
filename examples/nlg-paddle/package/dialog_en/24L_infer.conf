# job settings
task_name="dialog_en_24L_infer"
job_script="./scripts/distributed/infer.sh"
queue="nlp-32g-0-yq01-k8s-gpu-v100-8"
nodes=1
permission="private"

# k8s
fs_name="fs_name"
fs_ugi="username,password"
force_reuse_output_path="True"
output_path="/hdfs/path/to/output"

# afs
afs_fs_name="afs_fs_name"
afs_fs_ugi="username,password"
remote_mount_point="/afs/path/"
local_mount_point="/root/paddlejob/workspace/env_run/data/"

# hdfs
hdfs_path="hdfs_path"
hdfs_ugi="username,password"
hdfs_python_package=""
hdfs_init_model="/hdfs/path/to/model"

# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./package/dialog_en/vocab.txt"
spm_model_file="./package/dialog_en/spm.model"
infer_file="./data/dailydialog_test_60.tsv"
data_format="raw"
file_format="file"
config_path="./package/dialog_en/24L.json"

# inference settings
init_params="/path/to/model"
nsp_init_params="/path/to/NSP"
in_tokens="false"
batch_size=10

output_name="response"

# top-k sampling(k = 5) and rerank by length-average ppl(20 samples)
infer_args="--decoding_strategy topk_sampling --num_samples 20 --topk 5"
# top-k sampling(k = 5) and rerank by NSP score
# infer_args="--decoding_strategy topk_sampling --num_samples 20 --topk 5 --ranking_score nsp_score"
# top-p sampling(p = 0.9) and rerank by length-average ppl(20 samples)
# infer_args="--decoding_strategy topp_sampling --num_samples 20 --topp 0.9"
# beam_search(beam size = 10)
# infer_args="--decoding_strategy beam_search --beam_size 10"

log_dir="./log"
save_path="./output"
